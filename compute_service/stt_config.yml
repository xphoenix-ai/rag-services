hf:
  model_config:
    language: "en"
    # model_path: "openai/whisper-small"
    model_path: "openai/whisper-base"
    # model_path: "openai/whisper-large-v3"
    device: "cpu"
    # device: "cuda"
    torch_dtype: torch.float16
    model_kwargs:
      low_cpu_mem_usage: True
  generation_config:
    batch_size: 1
    generate_kwargs:
      do_sample: True
      top_k: 5
      num_return_sequences: 1

whisper:
  model_config:
    language: "en"
    # model_path: "small"
    model_path: "base"
    # model_path: "large-v3"
    device: "cpu"
  generation_config:
    fp16: False  # Set fp16=True if device is "cuda"
    